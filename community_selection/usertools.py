#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mar 09 2020
@author: changyuchang
"""
import numpy as np
import pandas as pd
from community_selection.A_experiment_functions import *
from community_selection.B_community_phenotypes import *
from community_selection.C_selection_algorithms import *
from community_selection.D_perturbation_algorithms import *
from community_selection.E_protocols import *


def plot_community_function(function_df):
	"""Plot community function"""
	function_df.plot.scatter(x = "Transfer", y = "CommunityPhenotype")

def plot_transfer_matrix(transfer_matrix):
	"""Plot transfer matrix"""
	import seaborn as sns
	fig,ax=plt.subplots()
	sns.heatmap(transfer_matrix,ax=ax)
	ax.set_xlabel('Old well',fontsize=14)
	ax.set_ylabel('New well',fontsize=14)
	ax.set_title(r'Transfer Matrix',fontsize=14)
	plt.show()

def make_assumptions(input_file, row):
	'''  Generate the assumptions dictionary from input file and row of input file '''
	#Load row dat and default assumptions
	row_dat = pd.read_csv(input_file, keep_default_na=False).iloc[row]
	assumptions = a_default.copy()
	original_params = MakeParams(assumptions.copy())
	#Update assumptions based on row_dat
	for k in row_dat.keys():
		#if NA default to original value 
		if k in assumptions.keys() and row_dat[k] != 'NA' :
			assumptions.update({k :row_dat[k]})
		elif k in assumptions.keys() and row_dat[k] == 'NA' :
			continue
		#some params for who we wan't to resort to there default value are not stored in assumptions but are generated by MakeParams
		elif k not in assumptions.keys() and k in original_params.keys() and row_dat[k] != 'NA':
			assumptions.update({k :row_dat[k]})
		elif k not in assumptions.keys() and k  in original_params.keys() and row_dat[k] == 'NA':
			assumptions.update({k:original_params[k]})
		else:
			if row_dat[k] != 'NA':
				assumptions.update({k :row_dat[k]})
			else:
				assumptions.update({k :np.nan})
	
	#These two assumptions are generated from combinations of other paramaters
	assumptions.update({'SA' :row_dat['sn']*np.ones(row_dat['sf'])  }) #Number of consumers in each Specialist family
	assumptions.update({'MA' :row_dat['rn']*np.ones(row_dat['rf'])  }) #Number of resources in each class
	
	#MakeParams does not work with numpy type for R0_food so convert to base python if not using default
	if not isinstance(assumptions['R0_food'],int):
		assumptions['R0_food'] = assumptions['R0_food'].item()
	
	#When running monoculture (every isolate in monoculture)
	if assumptions['monoculture'] :
		assumptions.update({"n_wells": int(np.sum(assumptions["SA"])  + assumptions["Sgen"])})
		
	#If knock_in isolate is True and no threshold is set threshold size defaults to 0
	if assumptions['bottleneck']:
		if  pd.isnull(assumptions['bottleneck_size']):
			assumptions['bottleneck_size'] =assumptions['dilution']
		else:
			assumptions['bottleneck_size'] = float(assumptions['bottleneck_size'])

	#If knock_in isolate is True and no threshold is set threshold size defaults to 0
	if assumptions['knock_in']:
		if pd.isnull(assumptions['knock_in_threshold']) :
			assumptions['knock_in_threshold'] =0
		else:
			assumptions['knock_in_threshold'] = float(assumptions['knock_in_threshold'])
		
	#If coalescence is True and no frac coalescence is set defaults to 50-50
	if assumptions['coalescence']:
		if pd.isnull(assumptions['frac_coalescence']):
			assumptions['frac_coalescence'] =0.5	
		else:
			assumptions['frac_coalescence'] = float(assumptions['frac_coalescence'])
	
	#If migration is True and no n_migration is set defaults to n_inoc
	if assumptions['migration']: 
		if pd.isnull(assumptions['n_migration']):
			assumptions['n_migration'] =assumptions['n_inoc']
		else:
			assumptions['n_migration'] = int(assumptions['n_migration'])
			
		if pd.isnull(assumptions['s_migration']):
			pass
		else:
			assumptions['s_migration'] = int(assumptions['s_migration'])
			
	#If coalescence is True and no frac coalescence is set defaults to 50-50
	if assumptions['resource_shift']:
		if pd.isnull(assumptions['r_percent']):
			assumptions['r_percent'] =0.1
		else:
			assumptions['r_percent'] = float(assumptions['r_percent'])
			
	# Overwrite plate
	if isinstance(assumptions["overwrite_plate"], str) and assumptions["overwrite_plate"] != "NA": 
		print("\n\nOverwriting the initial plate composition with input plate")
		df = pd.read_csv(assumptions["overwrite_plate"])
		assumptions["n_wells"] = len(set(df["Well"]))
	
	return assumptions

def prepare_experiment(assumptions):
	"""
	Prepare the experimental setup for this simulation
	
	assumptions = dictionary of metaparameters
	
	Return: params, params_simulation, params_algorithm,plate
	"""
	print("\nGenerate species paramaters")
	np.random.seed(assumptions['seed']) 
	#print(assumptions)
	params = MakeParams(assumptions) 
	
	print("\nDraw per-capita function and cost")
	f1_species_smooth, f1_species_rugged, f2_species_smooth, f2_species_rugged = draw_species_function(assumptions)
	params.update({"f1_species_smooth": f1_species_smooth, "f1_species_rugged": f1_species_rugged, "f2_species_smooth": f2_species_smooth, "f2_species_rugged": f2_species_rugged})
	gi = draw_species_cost(f1_species_smooth, assumptions)
	params.update({"g": gi})
	
	print("\nConstructing plate")
	np.random.seed(assumptions['seed']) 
	plate = make_plate(assumptions,params)
		
	print("\nAdd community function to plate")
	plate = add_community_function(plate, assumptions, params)
	
	if not pd.isnull(assumptions["overwrite_plate"]) :
		print("\nUpdating the initial plate composition by overwrite_plate")
		plate = overwrite_plate(plate, assumptions)
		
	print("\nPrepare Protocol")
	#Extract Protocol from protocol database
	algorithms = make_algorithms(assumptions)
	params_algorithm = algorithms[algorithms['algorithm_name'] == assumptions['protocol']]
	
	#Params_simulation by default  contains all assumptions not stored in params.
	params_simulation  =  dict((k, assumptions[k]) for k in assumptions.keys() if k not in params.keys())
	
	return params, params_simulation , params_algorithm, plate

def simulate_community(params, params_simulation, params_algorithm, plate):
    """
    Simulate community dynamics by given experimental regimes
    
    params = parameter passed from community-simulator
    params_simulation = dictionary of parameters for running experiment
    params_algorithm = dictionary of algorithms that determine the selection regime, migration regime, and community pheotypes
    plate = Plate object specified by community-simulator
    
    Return:
    community_composition = concatenated, melted panda dataframe of community and resource composition in each transfer
    community_function = melted panda dataframe of community function
    """
    print("\nStarting " + params_simulation["exp_id"])
    
    # Test the community function
    globals()[params_algorithm["community_phenotype"][0]](plate, params_simulation = params_simulation)
    try:
        community_function = globals()[params_algorithm["community_phenotype"][0]](plate, params_simulation = params_simulation) # Community phenotype
    except:
        print('\nCommunity phenotype test failed')
        raise SystemExit

    # Save the inocula composition
    if params_simulation['save_composition']:
        plate_data_list = list() # Plate composition
        plate_data = reshape_plate_data(plate, params_simulation,transfer_loop_index=0)  # Initial state
        plate_data_list.append(plate_data)
        composition_filename = params_simulation['output_dir'] + params_simulation['exp_id'] + '_composition.txt'   
        
    # Save the initial community function + richness + biomass
    if params_simulation['save_function']:
        community_function_list = list() # Plate composition
        richness = np.sum(plate.N >= 1/params_simulation["scale"], axis = 0) # Richness
        biomass = list(np.sum(plate.N, axis = 0)) # Biomass
        function_data = reshape_function_data(params_simulation,community_function, richness, biomass, transfer_loop_index =0)
        community_function_list.append(function_data)
        function_filename = params_simulation['output_dir'] + params_simulation['exp_id'] + '_function.txt'   


    print("\nStart propogation")
    # Run simulation
    for i in range(0, params_simulation["n_transfer"]):
        # Algorithms used in this transfer
        phenotype_algorithm = params_algorithm["community_phenotype"][i]
        selection_algorithm = params_algorithm["selection_algorithm"][i]
        print("Transfer " + str(i+1))

        # Propagation
        plate.Propagate(params_simulation["n_propagation"])
    
        # Measure Community phenotype
        community_function = globals()[params_algorithm["community_phenotype"][0]](plate, params_simulation = params_simulation) # Community phenotype
        
        # Append the composition to a list
        if params_simulation['save_composition'] and ((i+1) % params_simulation['composition_lograte'] == 0):
            plate_data = reshape_plate_data(plate, params_simulation,transfer_loop_index=i+1)  # Initial state
            plate_data_list.append(plate_data)

        if params_simulation['save_function'] and ((i+1) % params_simulation['function_lograte'] == 0):
            richness = np.sum(plate.N >= 1/params_simulation["scale"], axis = 0) # Richness
            biomass = list(np.sum(plate.N, axis = 0)) # Biomass
            function_data = reshape_function_data(params_simulation,community_function, richness, biomass, transfer_loop_index =i+1)
            community_function_list.append(function_data)

		#Store prior state before passaging (For coalescence)
        setattr(plate, "prior_N", plate.N)
        setattr(plate, "prior_R", plate.R)
        setattr(plate, "prior_R0", plate.R0)

        # Passage and tranfer matrix
        transfer_matrix = globals()[selection_algorithm](community_function)
        if params_simulation['monoculture']:
            plate = passage_monoculture(plate, params_simulation["dilution"])
        else:
            plate.Passage(transfer_matrix * params_simulation["dilution"])
        
        # Perturbation
        if params_simulation['directed_selection']:
            if selection_algorithm == 'select_top':
                plate = perturb(plate, params_simulation, keep = np.where(community_function >= np.max(community_function))[0][0])
            if selection_algorithm != 'select_top' and (params_algorithm.iloc[i]["algorithm_name"] != 'simple_screening'):
                plate = perturb(plate, params_simulation, keep = None)

    if params_simulation['save_composition']:
        pd.concat(plate_data_list).to_csv(composition_filename, index = False)
    if params_simulation['save_function']:
        pd.concat(community_function_list).to_csv(function_filename, index = False)
    print("\n" + params_simulation["exp_id"] + " finished")

def save_plate(assumptions, plate):
	""" 
	Save the initial plate in a pickle file. Like saving a frozen stock at -80C
	"""
	if assumptions['save_plate']:
		import dill as pickle
		with open(assumptions['output_dir'] + assumptions['exp_id'] + ".p", "wb") as f:
			pickle.dump(plate, f)
